22.9.2015, GN:

Note tagging with SVM-NER:
*******************************************************************************

tagging Conll 2003 types according to data define in

/Users/gune00/dfki/TIM-Tools/SvenTagger/NERtests/conll2003

models: trained on eng/deu.train.svm 
EN2003 -  testb F1=79.90%
DE2003 -  testb F1=61.37

models: trained on eng/deu.traintesta.svm 
EN2003 -  testb F1=80.56% (minus 11%)
DE2003 -  testb F1=66.58  (minus 11%)

Testing NER:
-> had to update corpus data as well!

eng.train -> mapped to conll format eng.train.conll via:
mapper.transcodeNERfile("resources/data/ner/eng.testb", "utf-8", "resources/data/ner/eng-testb.conll", "utf-8");

// I have adjusted the NER conll format to be consistent with the other conll formats, i.e.
// LONDON NNP I-NP I-LOC -> 1	LONDON	NNP	I-NP	I-LOC
// This is why I have 5 elements instead of 4 

Using cluster IDs:
*******************

***** With all sentences from CONLL-based unlabeled data:

lt-pool-223:resources gune00$ ./conlleval < eval/eng-testa.txt 
processed 51578 tokens with 5942 phrases; found: 6077 phrases; correct: 5332.
accuracy:  98.31%; precision:  87.74%; recall:  89.73%; FB1:  88.73
              LOC: precision:  92.31%; recall:  93.41%; FB1:  92.86
             MISC: precision:  83.99%; recall:  83.08%; FB1:  83.53
              ORG: precision:  78.55%; recall:  81.36%; FB1:  79.93
              PER: precision:  91.76%; recall:  95.49%; FB1:  93.59
lt-pool-223:resources gune00$ ./conlleval < eval/eng-testb.txt 
processed 46666 tokens with 5648 phrases; found: 5905 phrases; correct: 4811.
accuracy:  97.24%; precision:  81.47%; recall:  85.18%; FB1:  83.29
              LOC: precision:  85.65%; recall:  88.73%; FB1:  87.16
             MISC: precision:  72.43%; recall:  76.35%; FB1:  74.34
              ORG: precision:  74.86%; recall:  79.77%; FB1:  77.24
              PER: precision:  88.18%; recall:  90.91%; FB1:  89.52
              
***** Only with resources from training data: no unlabeled data and cluster data:
              
lt-pool-223:resources gune00$ ./conlleval < eval/eng-testa.txt 
processed 51578 tokens with 5942 phrases; found: 6069 phrases; correct: 5031.
accuracy:  97.52%; precision:  82.90%; recall:  84.67%; FB1:  83.77
              LOC: precision:  89.11%; recall:  90.85%; FB1:  89.97
             MISC: precision:  81.59%; recall:  80.26%; FB1:  80.92
              ORG: precision:  71.19%; recall:  75.91%; FB1:  73.48
              PER: precision:  86.28%; recall:  87.08%; FB1:  86.68
lt-pool-223:resources gune00$ ./conlleval < eval/eng-testb.txt 
processed 46666 tokens with 5648 phrases; found: 5983 phrases; correct: 4254.
accuracy:  95.63%; precision:  71.10%; recall:  75.32%; FB1:  73.15
              LOC: precision:  81.06%; recall:  84.95%; FB1:  82.96
             MISC: precision:  67.01%; recall:  74.64%; FB1:  70.62
              ORG: precision:  61.45%; recall:  68.33%; FB1:  64.71
              PER: precision:  73.35%; recall:  72.85%; FB1:  73.10
              
***** -> extra knowledge is important

***** Without suffix features:

lt-pool-223:resources gune00$ ./conlleval < eval/eng-testa.txt 
processed 51578 tokens with 5942 phrases; found: 6133 phrases; correct: 5154.
accuracy:  97.75%; precision:  84.04%; recall:  86.74%; FB1:  85.37
              LOC: precision:  89.16%; recall:  91.83%; FB1:  90.48
             MISC: precision:  77.47%; recall:  76.46%; FB1:  76.97
              ORG: precision:  72.73%; recall:  77.78%; FB1:  75.17
              PER: precision:  90.62%; recall:  93.32%; FB1:  91.95
lt-pool-223:resources gune00$ ./conlleval < eval/eng-testb.txt 
processed 46666 tokens with 5648 phrases; found: 6014 phrases; correct: 4632.
accuracy:  96.60%; precision:  77.02%; recall:  82.01%; FB1:  79.44
              LOC: precision:  79.96%; recall:  86.81%; FB1:  83.24
             MISC: precision:  67.25%; recall:  71.37%; FB1:  69.25
              ORG: precision:  68.15%; recall:  73.81%; FB1:  70.87
              PER: precision:  87.82%; recall:  90.11%; FB1:  88.95
              
-> suffix features are important

***** without cluster feature but anything else:

lt-pool-223:resources gune00$ ./conlleval < eval/eng-testa.txt 
processed 51578 tokens with 5942 phrases; found: 6126 phrases; correct: 5162.
accuracy:  97.80%; precision:  84.26%; recall:  86.87%; FB1:  85.55
              LOC: precision:  90.57%; recall:  90.96%; FB1:  90.77
             MISC: precision:  83.11%; recall:  81.13%; FB1:  82.11
              ORG: precision:  71.67%; recall:  76.21%; FB1:  73.87
              PER: precision:  88.03%; recall:  93.43%; FB1:  90.65
lt-pool-223:resources gune00$ ./conlleval < eval/eng-testb.txt 
processed 46666 tokens with 5648 phrases; found: 6042 phrases; correct: 4475.
accuracy:  96.19%; precision:  74.06%; recall:  79.23%; FB1:  76.56
              LOC: precision:  82.77%; recall:  83.51%; FB1:  83.14
             MISC: precision:  69.26%; recall:  73.50%; FB1:  71.32
              ORG: precision:  63.73%; recall:  71.40%; FB1:  67.35
              PER: precision:  78.72%; recall:  85.34%; FB1:  81.90
              
***** -> cluster features are important

***** Without unlabeled data:

lt-pool-223:resources gune00$ ./conlleval < eval/eng-testa.txt 
processed 51578 tokens with 5942 phrases; found: 6050 phrases; correct: 5303.
accuracy:  98.22%; precision:  87.65%; recall:  89.25%; FB1:  88.44
              LOC: precision:  91.89%; recall:  92.49%; FB1:  92.19
             MISC: precision:  85.45%; recall:  84.06%; FB1:  84.75
              ORG: precision:  78.07%; recall:  82.55%; FB1:  80.25
              PER: precision:  91.79%; recall:  93.49%; FB1:  92.63
lt-pool-223:resources gune00$ ./conlleval < eval/eng-testb.txt 
processed 46666 tokens with 5648 phrases; found: 5913 phrases; correct: 4716.
accuracy:  96.95%; precision:  79.76%; recall:  83.50%; FB1:  81.58
              LOC: precision:  84.23%; recall:  87.41%; FB1:  85.79
             MISC: precision:  70.10%; recall:  76.50%; FB1:  73.16
              ORG: precision:  71.97%; recall:  77.12%; FB1:  74.46
              PER: precision:  88.02%; recall:  89.05%; FB1:  88.53
              
***** not so important

***** Without shape features, but anything else:

processed 51578 tokens with 5942 phrases; found: 5770 phrases; correct: 5102.
accuracy:  97.75%; precision:  88.42%; recall:  85.86%; FB1:  87.12
              LOC: precision:  91.45%; recall:  87.97%; FB1:  89.68
             MISC: precision:  87.70%; recall:  78.85%; FB1:  83.04
              ORG: precision:  78.53%; recall:  78.30%; FB1:  78.42
              PER: precision:  93.03%; recall:  92.78%; FB1:  92.91
lt-pool-223:resources gune00$ ./conlleval < eval/eng-testb.txt 
processed 46666 tokens with 5648 phrases; found: 5588 phrases; correct: 4476.
accuracy:  96.48%; precision:  80.10%; recall:  79.25%; FB1:  79.67
              LOC: precision:  83.40%; recall:  79.50%; FB1:  81.40
             MISC: precision:  74.52%; recall:  72.08%; FB1:  73.28
              ORG: precision:  71.51%; recall:  74.35%; FB1:  72.90
              PER: precision:  88.51%; recall:  87.14%; FB1:  87.82
              
***** shape features are important

*****
Test with modelInfo="FLORS" and 1000 clusters, no word embedding

Training: 6491 msec, = 6 sec.

lt-pool-229:resources gune00$ ./conlleval < eval/eng-testb.txt 
processed 46666 tokens with 5648 phrases; found: 5911 phrases; correct: 4742.
accuracy:  97.04%; precision:  80.22%; recall:  83.96%; FB1:  82.05

*****
Test with modelInfo="FLORS" and 500 clusters, no word embedding

lt-pool-229:resources gune00$ ./conlleval < eval/eng-testb.txt 
processed 46666 tokens with 5648 phrases; found: 5910 phrases; correct: 4763.
accuracy:  97.11%; precision:  80.59%; recall:  84.33%; FB1:  82.42