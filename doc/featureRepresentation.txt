Implementing FLORS, Schnabel & Sch√ºtze, TACL, 2014
My extensions: 
cluster features, adaptation to NER


Idea is to train a one-vs-all POS-tagger and NE-tagger.

One-vs-all means: 
- for each tag train a model. Then, apply all models on new word and select best tag.
- is part of the Liblinear package.

Background from paper:

Local context for tagging word:
	window 2l+1 around token v_i: (v_i-l, .., v_i, ..., v_i+l)

	sentences are padded with <BOUNDARY> at the start/end
	
	if l = 2 -> 5-token window (v_i-2, v_i-1, v_i, v_i+1, v_i+2)

Representation of feature F for token v_i

	F(v_i) = f(v_i-l) conc ... conc f(v_i+l)
	
	
Word features: each word w is represented by max five components (components can be switched off/on)
(normalize each of the  component vectors to unit length. 
Calculate length of vector and then divide each component by length of vector) - do I do that ?:

f(w) = f_left(w) + f_right(w) + f_suffix(x) + f_shape(w) + f_cluster(w)

1. Distributed word feature:

f_left(w) ::=
	cell i gets value x_i = tf(freq(bigram(c_i, w)))
	"the ith entry named x_i is the weighted number of times 
		that the INDICATOR WORD c_i occurs immediately to the left of w"
	
	where c_i is the word with frequency rank i in the corpus.
	
f_right(w) analoguously.

restrict n=500 indicator words.

To avoid zero vectors: add additional cell n+1 and count omitted context.

text is preprocessed by lowercasing everything.

2. Suffix features: all suffixes of a word plus word:
	they compute 91.161 different suffix features from training data I guess
	
3. Shape features:
	Use Berkely parser word features.
	Each word is mapped to 16 bit string indicating ENGLISH orthography
	on WSJ: yields 50 different signatures (bit string instances).
	This gives 50 different shape features.

-> https://github.com/slavpetrov/berkeleyparser/blob/master/src/edu/berkeley/nlp/discPCFG/LexiconFeatureExtractor.java
-> https://github.com/slavpetrov/berkeleyparser/blob/master/src/edu/berkeley/nlp/discPCFG/LexiconFeature.java

4. Cluster features:
	I am using teh preprocessed clusters from Marmot (Mueller&Schuetze, ACL, 2015)
	use cluster ID as feature -> upto 1000 cluster ID names
	unknown words are mapped to clusterID of word <RARE>|<Rare>
