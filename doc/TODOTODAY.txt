15.9.2015:

- find error with missing signature
	- solved -> 
	  features.WordFeatures.fillShapeFeatures(String, int, Alphabet, boolean) does return an empty shape list (instead of NULL)

- use model file and label map file as parameter
	- solved -> define a class ModelInfo() and use it in trainer and tagger

- define evaluation method
	- done as part of tagger
	- I am using the original conll token and the predicted labels
	- and construct a version which consistent with conlleval

- check which tool for evaluation
	the one here: /Users/gune00/data/conll/conll03-NER/bin
	can also be used for NER
	
16.9.2015:

- define a single place for major resources -> DONE

- define main function to be used by exectuable -> DONE

- train larger models -> DONE

17.9.2015

- allow training without selected features -> DONE

- allow run shells with parameters and defaults -> DONE

22.9.2015:

- first tests with NER -> DONE
	- results are not optimal, even worst than with SvmNER and MdpNER, but probably because shape and suffix features etc.
	- results with conlleval look a bit strange -> use therefore average FB1 over types
	- so need to create own version for NER

23.9.2015:
- also count unknown and known word accuracies -> DONE

- check whole code again:
	- handle GNTrainer bugs -> DONE
	- "<BOUNDARY>" in window 
		-> dummy strings that are needed if index of current token is near beginning/end of sentence
		-> note that this means that context cannot cross sentence border -> OK?
		
- I am using now "<BOUNDARY>" also for "<s>" and "</s>"
	
13.10.2015:

- add to training phase generation of shape features and suffix list -> DONE
- collect all data using taggerName as part of filenames -> DONE

- integrate cluster based features -> DONE!!

-> correct bug in features.WordFeatures.setOffSets() -> DONE
-> need to apdate GNT.java -> using "DUMMY" source cluster file -> DONE

- unknown word handling for distributed word vectors: cf. tagging.txt -> DONE
	BUT none effective because all unlabeled data is used for computing distributed word vectors

- use ngrams instead of suffix (simulates NemexA) -> DONE, but check again
	switch off/on: WordSuffixFeatureFactory.ngram = false;

November, 2015:

- normalize digits to 0 -> DONE
	- /GNT/doc/corpus.txt

- run GNT on German POS and NER -> DONE


HIERIX:

- check to normalize/scale each component vector
	to unit length (compute length of vector, and then divide each component)
	I think I for got it 
	-> I am doing it now on complete feature vector in 
		trainer.ProblemInstance.createProblemInstanceFromWindow(Window)

- use other word embedding -> word2vec

- create property file

- save and move it to model file folder

- create input file for TORCH

- NER-lexikons

- character embeddings

- run GNT with suffix AND ngram by concatenating both into one file
	- DONE -> errors when concatenation -> I forgot to sort again after adding indices in 
		features.WordSuffixFeatureFactory.getAllKnownSubstringsForWord(String)
		
- compute all prefixes AND eventually combine with suffixes

- use GNT also for chunking

- can I use GNT for relation extraction ?

- map GNT feature vector also to torch input and run neuronal networks
		
- add FLORS accuracy to evaluation script

- generated compressed folder of all data that is necessary for tagging
- define logger
- define parallel processing


	

	