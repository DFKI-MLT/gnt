August, 2016:


My idea of defining a cascade of liblinear learners seems to be 
what is known as recurrent Machine Learning;

It should be possible to integrate the labels from the window elements (as well as the predicted onces)
from left to right (only ??)

via 
tagger.GNTagger.createWindowFramesFromSentence()
tagger.GNTagger.constructProblemAndTag(boolean, boolean)
Could be similar to
features.WordFeatures.fillClusterIdFeatures(String, Alphabet, boolean)

Steps:

Training:

- define a feature for predictedLabels
	feature vector can be built from known label set
- initialize data.OffSets.initializeOffsets(Alphabet, int)
- label set should be known anyway so no need to load it during training and tagging
	- but add as predicate to Alphabet
	- use |labelSet|+1 or -1 for unknown
	
- adapt trainer.TrainerInMem.constructProblem(boolean, boolean)
	- create predictedLabels feature for left window context in data.Window.fillWindow(boolean, boolean)
	- data.Window.createWordFeatures(Sentence, String, int, int, boolean, boolean) add boolean parameter recurrent
		- controls whether predicted labels are used or not (in that case a dummy predicted label is used
	- set off sets via features.WordFeatures.setOffSets(Alphabet, OffSets)
	- add new feature to features.WordFeatures and adapt like clusterId features
	- adjust feature vector in trainer.ProblemInstance.createProblemInstanceFromWindow(Window)

Tagging:
- labels are already loaded
- set up data.OffSets.initializeOffsets(Alphabet, int)
- I think it should be the same as in training, because labels are predicted left-to-right
	and overwrite the dummy cat