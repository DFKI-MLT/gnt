HIERIX: January 2016

- Create LibLinear Input file, so that C version can be called

- Use BIOES schema
	- see code in /nereid/src/main/java/de/dfki/lt/nereid/nep/BIO2BILOUtransformer.java
	- should be useful for NER

- Cluster from Jon Dehardy - clusterCat
	- run on source text on clusterCat and Marlin
	- use same parameters
		- number of cluster, frequency threshold, iterations
	- difference between clusterCat and Marlin:
		clusterCat uses "leftWord word rightWord bigrams" (similar to word clusters in GNT)
		Marlin uses "leftWord leftWord word" trigrams
	- Jon proposed to use clusters and cluster size as additional feature


- labeled: I have the twitter data from Ines Rehbein
	- XML format stehen in data/twitter_gold
	-> m端ssen noch nach CONLL transformiert werden

- Other corpora for DE-POS and DE-NER
	- Unlabeled Mannheim, google books, ...

- check to normalize/scale each component vector
	to unit length (compute length of vector, and then divide each component)
	I think I for got it 
	-> I am doing it now on complete feature vector in 
		trainer.ProblemInstance.createProblemInstanceFromWindow(Window)
	-> try it on relevant component feature!
	
- other shape features
	- cf. doc/LiblinearNER.txt
	- I think that this could be a source for improvement, and hence, do some research here

- use other word embedding -> word2vec -> 
	but actually only used in NER -> so check, whether really usable
	maybe better clustering or other co-occurrence  models (WebQA?)
	- character and other embeddings

- POS tags as feature for NER
	- how can I define a kind of pipeline model for GNT ?

- Use previous predicted tag as feature for POS/NER

- Generalisation:
	- filter out low frequencies of terms/suffixes
	
- Use of gazetteers:
	- instead of using it as feature, use it as pre/postfilter
	- use nemexa for exact match
	- learn to obtain optimal threshold for nemexf via regression analysis on training analysis
	- get NEs also from Wikidata
	
	- add to clusters entries which belong to 
		NE classes, e.g., cluserID 417 seems to cover first names
		define them as additional dictionaries and insert them when reading in clusterIds
		
- Test with uniform tag set
	- reuse java code in cf. /MDP/src/de/dfki/lt/nep/ConllNERmapper.java

- run GNT with suffix AND ngram by concatenating both into one file
	- DONE -> errors when concatenation -> I forgot to sort again after adding indices in 
		features.WordSuffixFeatureFactory.getAllKnownSubstringsForWord(String)
		
- compute all prefixes AND eventually combine with suffixes
	- or use as separate feature
	
- set un-frequent features to 0 -> cf. comments in MDP/doc/GN-TODO.txt

- Interface to TORCH

***
Feature learning:
- Idea: extract POS/NER dictionary of tagged tokens or sequences from training file
	- without any (?) preprocessing of token spelling
	
- Extract and apply dictionary on training file
	- should re-cover training file
	- analyze positive matches, partial matches and negative matches
	- check autoencoder for automatic feature generation

***
Additional applications:
- GNT for morphological tagging
	- combine POS and MORPH tags
	- according to Georg: simple concatenation
	- according to paper in M端ller et al., EMNLP 2013: 681 labels
	- current SOTA for pos+morph in M端ller&Sch端tze, ACL, 2015: 
		89,18% (MarLin) and 89,32% (FST-based MA from Charles University, Hajic) 
		
->	DONE; files are defined; DONE: insert into corpus
->  I get 681 different items -> LIBLINEAR exists with OoutOfMemoryError ********************************************
	-> initialized array will get too long in liblinear train;
	Size of needed array for MCM:
		Prob.N * N-Class -> 1,738,161 * 681 -> 1183687641 -> bits ?
		* double=64bits 
-> running on lns-87247 with Xmx=64g
-> DONE and WORKS:
- current results: devel = 89,13% (MarLin=90,78%), test = 86,94% (MarLin=89,18%, -2,24)

- GNT for lemmatization
	
- GNT also for chunking
	- should be very simple, but would eventually need POS tagging

- GNT for semantic role labeling/tagging

- GNT for relation extraction
	- maybe use a specific BIO-like annotation schema
	- check semantic role annotation
	
***
For software package:
- Do splitting

- create property file
- save and move it to model file folder
- add FLORS accuracy to evaluation script
- create input file for TORCH
- generated compressed folder of all data that is necessary for tagging
- define feature instances ala ClearNLP via XML
-> how to integrate feature extraction approach dynamically ?

- define logger
- define parallel processing


	

	