HIERIX: January 2016

- store model file also under taggerName feature dir

- check tokenisation of clusters for Marlion ! and the way I do it
	- eventually tokenize again

- check to normalize/scale each component vector
	to unit length (compute length of vector, and then divide each component)
	I think I forgot it 
	-> I am doing it now on complete feature vector in 
		trainer.ProblemInstance.createProblemInstanceFromWindow(Window)
	-> try it on relevant component feature!
-> UNDERSTAND, why not necessary !

- Interface to TORCH should be quite easy now

- Try out POS+MORPH for other languages

- Cluster from Jon Dehardy - clusterCat
	- run on source text on clusterCat and Marlin
	- use same parameters
		- number of cluster, frequency threshold, iterations
	- difference between clusterCat and Marlin:
		clusterCat uses "leftWord word rightWord bigrams" (similar to word clusters in GNT)
		Marlin uses "leftWord leftWord word" trigrams
	- Jon proposed to use clusters and cluster size as additional feature


- labeled: I have the twitter data from Ines Rehbein
	- XML format stehen in data/twitter_gold
	-> mÃ¼ssen noch nach CONLL transformiert werden

- Other corpora for DE-POS and DE-NER
	- Unlabeled Mannheim, google books, ...

- other shape features
	- cf. doc/LiblinearNER.txt
	- I think that this could be a source for improvement, and hence, do some research here

- use other word embedding -> word2vec -> 
	but actually only used in NER -> so check, whether really usable
	maybe better clustering or other co-occurrence  models (WebQA?)
	- character and other embeddings

- POS tags as feature for NER
	- how can I define a kind of pipeline model for GNT ?

- Use previous predicted tag as feature for POS/NER

- Generalisation:
	- filter out low frequencies of terms/suffixes
	
- Use of gazetteers:
	- instead of using it as feature, use it as pre/postfilter
	- use nemexa for exact match
	- learn to obtain optimal threshold for nemexf via regression analysis on training analysis
	- get NEs also from Wikidata
	
	- add to clusters entries which belong to 
		NE classes, e.g., cluserID 417 seems to cover first names
		define them as additional dictionaries and insert them when reading in clusterIds
		


- run GNT with suffix AND ngram by concatenating both into one file
	- DONE -> errors when concatenation -> I forgot to sort again after adding indices in 
		features.WordSuffixFeatureFactory.getAllKnownSubstringsForWord(String)
		
- compute all prefixes AND eventually combine with suffixes
	- or use as separate feature
	
- set un-frequent features to 0 -> cf. comments in MDP/doc/GN-TODO.txt

***
Feature learning:
- Idea: extract POS/NER dictionary of tagged tokens or sequences from training file
	- without any (?) preprocessing of token spelling
	
- Extract and apply dictionary on training file
	- should re-cover training file
	- analyze positive matches, partial matches and negative matches
	- check autoencoder for automatic feature generation

***
Additional applications:

- GNT for lemmatization
	
- GNT also for chunking
	- should be very simple, but would eventually need POS tagging

- GNT for semantic role labeling/tagging

- GNT for relation extraction
	- maybe use a specific BIO-like annotation schema
	- check semantic role annotation
	
***
For software package:
- create property file -> DONE
- save and move it to model file folder -> DONE
- add FLORS accuracy to evaluation script
- create input file for TORCH
- generated compressed folder of all data that is necessary for tagging
- define feature instances ala ClearNLP via XML
-> how to integrate feature extraction approach dynamically ?

- define logger
- define parallel processing
- do splitting according to
	

	

	