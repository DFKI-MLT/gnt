HIERIX: January 2016

- check to normalize/scale each component vector
	to unit length (compute length of vector, and then divide each component)
	I think I forgot it 
	-> I am doing it now on complete feature vector in 
		trainer.ProblemInstance.createProblemInstanceFromWindow(Window)
		
	-> try it on relevant component feature!
	-> according to LibLinear paper, normalize each instance vector which has non-zero values
		by value/sqrt(length of instance vector)
	-> NOTE: I should do it on relative feature vectors!
	
-> LEARN TO UNDERSTAND, why not necessary !

- *** take care of tokenization - currently just space

- Cluster from Jon Dehardy - clusterCat
- re-train clusters
	
- approximate matching for unknown words when looking up cluster map

- Other corpora for DE-POS and DE-NER
	- Unlabeled Mannheim, google books, ...

- other shape features
	- cf. doc/LiblinearNER.txt
	- I think that this could be a source for improvement, and hence, do some research here

- *** Use previous predicted tag as feature for POS/NER
	- cascaded LIBLINEAR ? sense-fully ?
	- how can I define a kind of pipeline model for GNT ?
	- via search-based structured prediction

- *** DO separate POS-tagging and MORPH tagging
	- learn different models
	- use in combined mod
	-> also means: cascaded liblinear

- *** Extract character distribution from labeled data

- use other word embedding -> word2vec -> 
	but actually only used in NER -> so check, whether really usable
	maybe better clustering or other co-occurrence  models (WebQA?)
	- character and other embeddings

- Use of gazetteers:
	- instead of using it as feature, use it as post-filter as part of tagger.PostProcessor.java
	- use nemexa for exact match
	- learn to obtain optimal threshold for nemexf via regression analysis on training analysis
	- get NEs also from Wikidata
	
	- add to cluster entries which belong to 
		NE classes, e.g., cluserID 417 seems to cover first names
		define them as additional dictionaries and insert them when reading in clusterIds
		
- run GNT with suffix AND ngram by concatenating both into one file
	- DONE -> errors when concatenation -> I forgot to sort again after adding indices in 
		features.WordSuffixFeatureFactory.getAllKnownSubstringsForWord(String)
		
- compute all prefixes AND eventually combine with suffixes
	- or use as separate feature
	
- set un-frequent features to 0 -> cf. comments in MDP/doc/GN-TODO.txt

***
Feature learning:
- Idea: extract POS/NER dictionary of tagged tokens or sequences from training file
	- without any (?) preprocessing of token spelling
	
- Extract and apply dictionary on training file
	- should re-cover training file
	- analyze positive matches, partial matches and negative matches
	- check autoencoder for automatic feature generation

***
Additional applications:

- GNT for lemmatization
	
- GNT also for chunking
	- should be very simple, but would eventually need POS tagging

- GNT for semantic role labeling/tagging

- GNT for relation extraction
	- maybe use a specific BIO-like annotation schema
	- check semantic role annotation
	
***
For software package:

- make it thread save

- add FLORS accuracy to evaluation script

- create input file for TORCH

- integrate learned models into jar-FILE -> usefull for using GNT with FLINK
	- create runtime-specific jar file with all dependencies and resources to run a tagger
	- create MODEL-specific jar files -> in order to restrict size of jar
	
- define feature instances ala ClearNLP via XML
-> how to integrate feature extraction approach dynamically ?

- define logger
- define parallel processing
- do splitting according
	

	

	