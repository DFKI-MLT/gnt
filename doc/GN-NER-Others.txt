GN on 13.12.2013:

*******************************************
Useful NE-specific features for GERMAN used by others:

***********
Grzegorz Chrupala, Dietrich Klakow (LREC, 2010): FOR GERMAN

-> their best result: 74.69%

We extract features of the current token to be labeled (con-
tent features) as well as features of a 5-token window cen-
tered around the current position (context features):
Content features
	– Word form
	– Lowercase word form
	– Lemma
	– Suffixes of length 1..3
	– Word shape: encodes which character classes
		(upper-case, lower-case, digits, or punctuation)
		the word contains and in what order
	– POS label
	– Chunk label

Context features
	– Word form for tokens at positions {-2, -1, 1, 2}
	– NE label at position -1
	– Concatenated NE labels at positions -2 and -1
	
Additional:
Automatically labeled data from 32 million pages using Brown clustering
and Wikipedia info boxes for extracting additional data.

Baseline:
Just data from CONLL-2003: ~63% F
Adding Wikipedia-Infoboxes: ~67% F
Adding Cluster: best result see below

	
Entity Precision Recall F-score
All 82.19 (31.32) 71.72 (34.16) 76.60** (34.18)
LOC 76.85 (22.16) 79.85 (41.39) 78.32 (32.55)
MISC 77.06 (18.33) 55.54 (28.27) 64.56 (29.49)
ORG 81.20 (05.86) 61.97 (22.89) 70.29 (21.69)
PER 90.72 (63.46) 85.15 (51.85) 87.85 (56.95)
Table 2: NER results on German development set. Numbers
in brackets show relative error reduction compared to
the baseline

Entity Precision Recall F-score
All 80.28 (18.21) 69.83 (22.46) 74.69** (21.67)
LOC 76.44 (12.71) 74.30 (23.56) 75.36 (19.13)
MISC 71.37 (11.61) 52.84 (17.28) 60.72 (17.22)
ORG 73.46 (03.39) 56.92 (11.67) 64.14 (10.24)
PER 91.59 (48.66) 83.85 (40.07) 87.55 (43.46)
Table 3: NER results on German test set. Numbers in
brackets show relative error reduction compared to the
baseline

***********
Using CRF-StanfordNER for GERMAN: 
/Users/gune00/dfki/MDPFrameWork/MDNER/konvens10_faruqui.pdf. FOR GERMAN

-> their best result: 78.2%

 Tokens Clusters Precision Recall F1
Baseline (0/0) 80.9 58.8 68.1
10M 100 85.2 68.1 75.7
10M 200 85.2 66.8 74.9
20M 100 83.0 64.9 72.9
20M 200 86.4 70.1 77.4
50M 200 86.7 69.3 77.0
50M 400 87.3 71.5 78.6
100M 200 85.4 69.4 76.6
100M 400 86.7 76.0 77.8
175M 200 86.2 71.3 78.0
175M 400 87.2 71.0 78.3
175M 600 88.0 72.9 79.8
Table 1: Performance on CoNLL German TestA development
set, using HGC as generalization corpus

Tokens Clusters Precision Recall F1
Baseline (0/0) 80.9 58.8 68.1 (stanford ner without distr. semantics)
10M 100 83.5 65.5 73.4
10M 200 84.1 66.0 73.9
20M 100 84.2 66.2 74.1
20M 200 84.1 66.8 74.5
50M 200 85.4 68.9 76.3
50M 400 85.1 68.9 76.1
100M 200 84.9 68.6 75.9
100M 400 84.8 69.1 76.1
175M 200 85.0 69.4 76.4
175M 400 86.0 70.0 77.2
175M 600 85.4 69.3 76.5
Table 2: Performance on CoNLL German TestA development
set, using deWac as generalization corpus

Model Precision Recall F1
Florian et al. (2003) 83.9 63.7 72.4**

Baseline (0/0) 84.5 63.1 72.3** (Stanford-NER without distr. semantics)
HGC (175M/600) 86.6 71.2 78.2** -> best result
deWac (175M/400) 86.4 68.5 76.4**
Table 3: Comparison to best CoNLL 2003 results for
German on the CoNLL TestB test dataset

NOTE:
Stanford-NER is a CRF-learner features:
word features: current word, previous word, next word, all words within a window 
Orthographic features: Jenny -> Xxxx, IL-2 -> XX-#
Prefixes and Suffixes: Jenny <J, <Je, <Jen, ..., nny>, ny>, y>
Label sequences
Lots of feature conjunctions 

*******************************************
Useful NE-specific features for ENGLISH used by others:

***********
http://www.cs.bgu.ac.il/~elhadad/nlp09/hw2.html#svm:

Here is a list of features that have been found appropriate for NER in previous work:

    The word form (the string as it appears in the sentence)
    The POS of the word
    ORT - a feature that captures the orthographic (letter) 
    		structure of the word. It can have any of the following values: 
    		number, contains-digit, contains-hyphen, capitalized, all-capitals, 
    		URL, punctuation, regular.
    prefix1: first letter of the word
    prefix2: first two letters of the word
    prefix3: first three letters of the word
    suffix1: last letter of the word
    suffix2: last two letters of the word
    suffix3: last three letters of the word 
    
***********
Paper by Turian et al., 2010, ACL
    
- Previous two predictions yi−1 and yi−2
- Current word xi
- xi word type information: 
	all-capitalized,
	is-capitalized, 
	all-digits, 
	alphanumeric, etc.
- Prefixes and suffixes of xi, if the word contains
	hyphens, then the tokens between the hyphens
- Tokens in the window c = (xi−2, xi−1, xi, xi+1, xi+2)
- Capitalization pattern in the window c
- Conjunction of c and yi−1.

89.41 % F1

***********
Paper at http://arxiv.org/pdf/1312.5542v1.pdf:

ENGLISH:
word embeddings (window size 5) and a capital letter feature. The “caps” feature tells if
each word was in lowercase, was all uppercase, had first letter capital, 
or had at least one non-initial capital letter. 

Result: best F1 for English: 89.16% 

****** Current best results which I found:

Current best result for EN: 91.67% -> /Users/gune00/dfki/MDPFrameWork/MDNER/McKanzie-2013.pdf

Current best result for DE: 81.60% -> dictionary-based approach (using tries, 10 million entries)	
(A Weikum student)