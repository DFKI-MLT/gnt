September, 15th, 2015:

NER - soon test GNT for NER:

October, 15th, 2015:

Integration of cluster in training and testing:
	- corpus see: /Users/gune00/data/Marmot/Word
	
-> DONE

- improved unknown word handling for distributed vectors
-> incremental adjustment of weights
-> DONE- BUT only effective when words are not in unlabeled data

- DONE: instead of suffix use trigrams -> is this similar to NemexA?

- more testing of liblinear itself ?

Parallel processing

Morphological tagging:
-> with the help of the dictionaries in /Users/gune00/data/Marmot/Word

Can I use it as a generic tagging tool
- opinion mining ?
- other machine learning tools?

QUESTIONS CONCERNING UNLABELED DATA:

THINK: why does clustering help?
	- clustering computes a classification of words into classes
	- thus, if I have an unknown word, but it is clustered into the same class as a word that was known during training
	- then the learner can just use the learned features
	
	- but if a word belongs to a class that was not observed in training, it will use this class as feature value any way
	- BUT what does this mean for the learner and the learned model?
	-> in principle this should also be true when using POS classes

THINK: about distributed vector representations
	- currently, they are used for representing words
	- the vectors are build on basis of indicator words, which define the dimension, i.e., the vector space
	
	- I think the same behavior as above also is correct here:
		if a word has a distributed vector which was not used during labeled training, 
		the tagger will use it to fill the feature vector in any case
		
SO WHAT does this mean? 
- is it correct to use the "unknown" feature values?