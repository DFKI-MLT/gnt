October, 2015:

- using windowSize=1 hurts !
- using windowSize=3 neutral

- neither 1grams nor 3grams bring anything

- smaller suffixes
-> initial test with suffix <= 5 brings a bit for EN, but hurts for DE
-> suffix <= 3 hurts for EN and DE

- generalization of number/date expressions
-> not useful so far (cf. doc/corpus.txt)

- it seems that only dimension around 50 brings something
-> also Turian et al. 2010 only use 50-dims for their word embedding stuff

- Actually, it is unclear, whether GNT features are usable for NER
-> check again paper from Tkachenko & Simanovsky

So, actually, what do I use:

I use this for both EN and DE

-	normalized text: lower case
-	no digit normalization
-	window size: 2
-	no subsampling
-	50 dim indicator words
-	all but only conll-data as unlabeled data
-	shape feature methods from POS tagger for EN and DE
-	all suffix features from training
-	1000 clusterIDs from Marmot
	- NOTE: Marmot cluserID are based on digit-normalized wiki-dumps

Test on DE:
-> best result: 68,41 F1

-> ablation tests (testb):
	cluster and 
	unlabeled features:	-10,42
	cluster features:	-6,87
	unlabeled features: -1,71
	suffix features:	-7,08	
	shape features:		-1,02

Test on EN:
-> best result: 82.14 F1 (82.84 with suffix-length <= 5):

-> ablation tests (testb):
	cluster and 
	unlabeled features:	-8,99
	cluster features:	-5,58	
	unlabeled features:	-0,56
	suffix features:	-2,7	
	shape features:		-2,47	

New possible features:

Alternative indicator words:
- What if I select indicator words those that occur in training data
	- select the context words from annotated strings 
	and choose the highest ranked words found in all indicator words
	
NER lexicons:
	- although I have word clusters, it might be too low
	- so very large NE lists could make sense
	- or retraining of Marmot cluster using own data files

POS

prefixes



