October, 2015:

- using windowSize=1 hurts !
- using windowSize=3 neutral

- changes in suffix list does not improve either

-> it seems that only dimension around 50 brings something
-> also Turian et al. 2010 only use 50-dims for their word embedding stuff

-> try out better unknown word features

-> Actually, it is unclear, whether GNT features are usable for NER
-> check again paper from Tkachenko & Simanovsky

So, actually, what do I use:

I use this for both EN and DE

-	normalized text: lower case
-	window size: 2
-	no distributed word features or 50 dim indicator words
-	shape feature methods from POS applied on training
-	all suffix features from training
-	1000 clusterIDs from Marmot
	- NOTE: Marmot cluserID are based on digit-normalized wiki-dumps

OBACHT: applies to both EN and DE:
- ich hatte vergessen, test unlabeled data zu laden, was dazu führte, dass ich viele unknown word habe
	wenn ich distributed vector baue -> das hat zu Verlusten geführt
- Now, i get better results again, but missing 1% in case of eng-testb.conll
-> Now, the differences with previous tests is that I now use all sentences from unlabeded data, not only the first 1000
-> trie again with fewer unlabeled data
	- not using unlabeled large corpus PTB
	- NEXT: try out: load only 1000
-> THUS: it seems that size of unlabeled data is important, maybe even domain wrt. NER types to classify?


Alternative indicator words:
- What if I select indicator words those that occur in training data
	- select the context words from annotated strings and choose the highest ranked words found in all indicator words


New possible features:

NER lexicons

character embeddings

POS

previous predictions

prefixes

smaller suffixes/prefixes
-> initial test with token <= 5 brings a bit for EN, but hurts for DE
-> token <= 3 hurts for EN and DE

generalization of number/date expressions
-> not useful so far (cf. doc/corpus.txt)

context elements without certain features
