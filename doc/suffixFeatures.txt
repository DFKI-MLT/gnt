

Goal is to compute all lower-case suffixes from a training set of words.
 * For suffix s, we set the dimension corresponding to s in f_suffix(w) to 1 if lowercased w ends in s 
 * and to 0 otherwise. Note that w is a suffix of itself.
 * In FLORS: 91,161 suffix features from PTB - I guess - and PTB has about 32.500 words.
 
 It is unclear how FLORS defines words from which suffixes should be created
-> for that reason I am using all tokens


I currently use only labeled training data:
- "resources/data/sancl-2012/sancl.labeled/ontonotes-wsj-train"

which gives me 91,151 suffixes
	
- since suffix features are binary, only those which are seen in labeled training can be used for learning
- so unlabeled data is not useful for suffixes from training, 
	because they are NOT used for distributed representations of suffixes
	
Lower dimensions:

in previous paper, FLORS uses only 100 highest ranked suffixes
-> TEST this as well

- can also use other kinds of suffixes, e.g., for German just Morphix tree

- or for NER, only upto N-suffixes

Computation of ngrams instead of suffixes: DONE
	switch off/on: WordSuffixFeatureFactory.ngram = false;

- map a word to a list of ngrams
	- only consider unique ngrams because of indexing
	- computes a signature for word
	- is this new for POS and NER?
- adapt code in
	- features.WordSuffixFeatureFactory.computeNgramsAndStore(String)
	- features.WordSuffixFeatureFactory.getAllKnownNgramsForWord(String)
-> both suffix and ngram are now covered by 
	- features.WordSuffixFeatureFactory.computeSubstringsAndStore(String)
	- features.WordSuffixFeatureFactory.getAllKnownSubstringsForWord(String)
	
Combine suffix and ngram by concatenating both into same file
	- 	simple concat does not help because it seems that I can not compute absolute enumeration for 
		resulting features
	-	eventually I need to define it as its own feature vector

Compute prefixes - might be useful for NER (is used as feature their)
